{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 03: Limpeza e Preparação de Dados\n",
    "\n",
    "**Objetivo:** Ensinar técnicas fundamentais para preparar dados para análise e modelagem.\n",
    "\n",
    "Nesta aula, exploraremos as etapas cruciais de limpeza e preparação de dados, que são essenciais para garantir a qualidade e a usabilidade dos dados em qualquer projeto de ciência de dados.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula 1: Importação das Bibliotecas Necessárias\n",
    "Primeiro, vamos importar as bibliotecas que usaremos, principalmente o `pandas` para manipulação de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configurações para melhor visualização\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula 2: Carregamento do Dataset\n",
    "Para o nosso projeto prático, vamos simular o carregamento de um dataset sobre empregos e salários.\n",
    "Em um cenário real, você carregaria seu próprio arquivo (e.g., CSV, Excel, JSON).\n",
    "\n",
    "Para fins de demonstração, criaremos um DataFrame de exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Original:\n",
      "   ID                   Cargo  Experiencia_Anos  Salario_Anual_USD     Localizacao       Educacao Data_Contratacao  Avaliacao_Desempenho Empresa_Tamanho  Bonus_Percentual\n",
      "0   1      Cientista de Dados               3.0              85000       São Paulo       Mestrado       2022-01-15                   4.5          Grande              0.10\n",
      "1   2  Engenheiro de Software               5.0             120000          Remoto      Graduação       2020-05-20                   4.8           Média              0.15\n",
      "2   3       Analista de Dados               2.0              60000  Rio de Janeiro      Graduação       2023-03-10                   3.9         Pequena              0.05\n",
      "3   4      Cientista de Dados               NaN              90000  Belo Horizonte       Mestrado       2021-11-01                   4.2          Grande              0.12\n",
      "4   5      Gerente de Projeto               8.0             150000       São Paulo  Pós-Graduação       2018-07-25                   4.9          Grande              0.20\n",
      "\n",
      "Informações do DataFrame Original:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12 entries, 0 to 11\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   ID                    12 non-null     int64  \n",
      " 1   Cargo                 12 non-null     object \n",
      " 2   Experiencia_Anos      10 non-null     float64\n",
      " 3   Salario_Anual_USD     12 non-null     int64  \n",
      " 4   Localizacao           12 non-null     object \n",
      " 5   Educacao              12 non-null     object \n",
      " 6   Data_Contratacao      12 non-null     object \n",
      " 7   Avaliacao_Desempenho  12 non-null     float64\n",
      " 8   Empresa_Tamanho       12 non-null     object \n",
      " 9   Bonus_Percentual      12 non-null     float64\n",
      "dtypes: float64(3), int64(2), object(5)\n",
      "memory usage: 1.1+ KB\n",
      "\n",
      "Estatísticas Descritivas do DataFrame Original:\n",
      "               ID               Cargo  Experiencia_Anos  Salario_Anual_USD Localizacao   Educacao Data_Contratacao  Avaliacao_Desempenho Empresa_Tamanho  Bonus_Percentual\n",
      "count   12.000000                  12         10.000000          12.000000          12         12               12             12.000000              12         12.000000\n",
      "unique        NaN                   8               NaN                NaN           5          4               12                   NaN               3               NaN\n",
      "top           NaN  Cientista de Dados               NaN                NaN   São Paulo  Graduação       2022-01-15                   NaN          Grande               NaN\n",
      "freq          NaN                   4               NaN                NaN           4          6                1                   NaN               6               NaN\n",
      "mean     6.500000                 NaN          4.100000       95833.333333         NaN        NaN              NaN              4.341667             NaN          0.112500\n",
      "std      3.605551                 NaN          2.330951       32333.020929         NaN        NaN              NaN              0.375278             NaN          0.053788\n",
      "min      1.000000                 NaN          1.000000       55000.000000         NaN        NaN              NaN              3.700000             NaN          0.030000\n",
      "25%      3.750000                 NaN          2.250000       68250.000000         NaN        NaN              NaN              4.075000             NaN          0.075000\n",
      "50%      6.500000                 NaN          3.500000       91000.000000         NaN        NaN              NaN              4.350000             NaN          0.105000\n",
      "75%      9.250000                 NaN          5.750000      122500.000000         NaN        NaN              NaN              4.625000             NaN          0.155000\n",
      "max     12.000000                 NaN          8.000000      150000.000000         NaN        NaN              NaN              4.900000             NaN          0.200000\n"
     ]
    }
   ],
   "source": [
    "# Criando um DataFrame de exemplo para simular um dataset de empregos e salários\n",
    "data = {\n",
    "    'ID': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "    'Cargo': ['Cientista de Dados', 'Engenheiro de Software', 'Analista de Dados', 'Cientista de Dados', 'Gerente de Projeto', 'Analista de BI', 'Engenheiro de ML', 'Cientista de Dados', 'Desenvolvedor Web', 'Analista de Dados', 'Engenheiro de Dados', 'Cientista de Dados'],\n",
    "    'Experiencia_Anos': [3, 5, 2, np.nan, 8, 4, 6, 3, 1, 2, 7, np.nan],\n",
    "    'Salario_Anual_USD': [85000, 120000, 60000, 90000, 150000, 70000, 130000, 92000, 55000, 63000, 140000, 95000],\n",
    "    'Localizacao': ['São Paulo', 'Remoto', 'Rio de Janeiro', 'Belo Horizonte', 'São Paulo', 'Remoto', 'São Paulo', 'Rio de Janeiro', 'Curitiba', 'São Paulo', 'Remoto', 'Belo Horizonte'],\n",
    "    'Educacao': ['Mestrado', 'Graduação', 'Graduação', 'Mestrado', 'Pós-Graduação', 'Graduação', 'Mestrado', 'Doutorado', 'Graduação', 'Graduação', 'Mestrado', 'Graduação'],\n",
    "    'Data_Contratacao': ['2022-01-15', '2020-05-20', '2023-03-10', '2021-11-01', '2018-07-25', '2021-09-12', '2019-02-01', '2022-06-30', '2024-01-05', '2023-08-18', '2019-10-10', '2022-04-22'],\n",
    "    'Avaliacao_Desempenho': [4.5, 4.8, 3.9, 4.2, 4.9, 4.1, 4.7, 4.3, 3.7, 4.0, 4.6, 4.4],\n",
    "    'Empresa_Tamanho': ['Grande', 'Média', 'Pequena', 'Grande', 'Grande', 'Média', 'Grande', 'Pequena', 'Média', 'Grande', 'Grande', 'Média'],\n",
    "    'Bonus_Percentual': [0.10, 0.15, 0.05, 0.12, 0.20, 0.08, 0.18, 0.10, 0.03, 0.06, 0.17, 0.11]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"DataFrame Original:\")\n",
    "print(df.head())\n",
    "print(\"\\nInformações do DataFrame Original:\")\n",
    "df.info()\n",
    "print(\"\\nEstatísticas Descritivas do DataFrame Original:\")\n",
    "print(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula 3: Tratamento de Valores Ausentes (`dropna()`, `fillna()`)\n",
    "\n",
    "Valores ausentes (NaN, None, NaT) são comuns em datasets e podem impactar negativamente a análise.\n",
    "Existem duas abordagens principais para lidar com eles:\n",
    "\n",
    "* **Remoção (`dropna()`):** Remover linhas ou colunas que contêm valores ausentes.\n",
    "* **Preenchimento (`fillna()`):** Preencher os valores ausentes com um valor específico (média, mediana, moda, um valor constante, etc.).\n",
    "\n",
    "#### 3.1 Identificando Valores Ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores Ausentes por Coluna antes do tratamento:\n",
      "ID                      0\n",
      "Cargo                   0\n",
      "Experiencia_Anos        2\n",
      "Salario_Anual_USD       0\n",
      "Localizacao             0\n",
      "Educacao                0\n",
      "Data_Contratacao        0\n",
      "Avaliacao_Desempenho    0\n",
      "Empresa_Tamanho         0\n",
      "Bonus_Percentual        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nValores Ausentes por Coluna antes do tratamento:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Removendo Linhas com Valores Ausentes (`dropna()`)\n",
    "Se a quantidade de valores ausentes for pequena e não comprometer a análise, podemos simplesmente remover as linhas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame após remover linhas com valores ausentes:\n",
      "   ID                   Cargo  Experiencia_Anos  Salario_Anual_USD     Localizacao       Educacao Data_Contratacao  Avaliacao_Desempenho Empresa_Tamanho  Bonus_Percentual\n",
      "0   1      Cientista de Dados               3.0              85000       São Paulo       Mestrado       2022-01-15                   4.5          Grande              0.10\n",
      "1   2  Engenheiro de Software               5.0             120000          Remoto      Graduação       2020-05-20                   4.8           Média              0.15\n",
      "2   3       Analista de Dados               2.0              60000  Rio de Janeiro      Graduação       2023-03-10                   3.9         Pequena              0.05\n",
      "4   5      Gerente de Projeto               8.0             150000       São Paulo  Pós-Graduação       2018-07-25                   4.9          Grande              0.20\n",
      "5   6          Analista de BI               4.0              70000          Remoto      Graduação       2021-09-12                   4.1           Média              0.08\n",
      "\n",
      "Valores Ausentes após dropna():\n",
      "ID                      0\n",
      "Cargo                   0\n",
      "Experiencia_Anos        0\n",
      "Salario_Anual_USD       0\n",
      "Localizacao             0\n",
      "Educacao                0\n",
      "Data_Contratacao        0\n",
      "Avaliacao_Desempenho    0\n",
      "Empresa_Tamanho         0\n",
      "Bonus_Percentual        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_dropped = df.dropna()\n",
    "print(\"\\nDataFrame após remover linhas com valores ausentes:\")\n",
    "print(df_dropped.head())\n",
    "print(\"\\nValores Ausentes após dropna():\")\n",
    "print(df_dropped.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Preenchendo Valores Ausentes (`fillna()`)\n",
    "Preencher valores ausentes é geralmente preferível à remoção, pois preserva mais dados.\n",
    "A estratégia de preenchimento depende do tipo de dado e do contexto.\n",
    "\n",
    "* **Para colunas numéricas:** Média, mediana, ou um valor constante.\n",
    "* **Para colunas categóricas:** Moda ou uma categoria 'Desconhecido'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame após preencher 'Experiencia_Anos' com a mediana:\n",
      "   ID                   Cargo  Experiencia_Anos  Salario_Anual_USD     Localizacao       Educacao Data_Contratacao  Avaliacao_Desempenho Empresa_Tamanho  Bonus_Percentual\n",
      "0   1      Cientista de Dados               3.0              85000       São Paulo       Mestrado       2022-01-15                   4.5          Grande              0.10\n",
      "1   2  Engenheiro de Software               5.0             120000          Remoto      Graduação       2020-05-20                   4.8           Média              0.15\n",
      "2   3       Analista de Dados               2.0              60000  Rio de Janeiro      Graduação       2023-03-10                   3.9         Pequena              0.05\n",
      "3   4      Cientista de Dados               3.5              90000  Belo Horizonte       Mestrado       2021-11-01                   4.2          Grande              0.12\n",
      "4   5      Gerente de Projeto               8.0             150000       São Paulo  Pós-Graduação       2018-07-25                   4.9          Grande              0.20\n",
      "\n",
      "Valores Ausentes após fillna():\n",
      "ID                      0\n",
      "Cargo                   0\n",
      "Experiencia_Anos        0\n",
      "Salario_Anual_USD       0\n",
      "Localizacao             0\n",
      "Educacao                0\n",
      "Data_Contratacao        0\n",
      "Avaliacao_Desempenho    0\n",
      "Empresa_Tamanho         0\n",
      "Bonus_Percentual        0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31144/2361416507.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_filled['Experiencia_Anos'].fillna(median_experiencia, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Criando uma cópia para não alterar o DataFrame original para as próximas demonstrações\n",
    "df_filled = df.copy()\n",
    "\n",
    "# Preenchendo 'Experiencia_Anos' (numérico) com a mediana\n",
    "median_experiencia = df_filled['Experiencia_Anos'].median()\n",
    "df_filled['Experiencia_Anos'].fillna(median_experiencia, inplace=True)\n",
    "\n",
    "# Exemplo de preenchimento com um valor constante para uma coluna hipotética\n",
    "# df_filled['Outra_Coluna_Numerica'].fillna(0, inplace=True)\n",
    "\n",
    "# Para colunas categóricas, podemos preencher com a moda (valor mais frequente)\n",
    "# ou com uma string 'Desconhecido'\n",
    "# Por exemplo, se tivéssemos valores ausentes em 'Educacao':\n",
    "# mode_educacao = df_filled['Educacao'].mode()[0]\n",
    "# df_filled['Educacao'].fillna(mode_educacao, inplace=True)\n",
    "\n",
    "print(\"\\nDataFrame após preencher 'Experiencia_Anos' com a mediana:\")\n",
    "print(df_filled.head())\n",
    "print(\"\\nValores Ausentes após fillna():\")\n",
    "print(df_filled.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula 4: Correção de Tipos de Dados e Normalização\n",
    "\n",
    "Garantir que as colunas tenham o tipo de dado correto é fundamental para operações e análises.\n",
    "Normalização e padronização são técnicas usadas para escalar dados numéricos.\n",
    "\n",
    "#### 4.1 Correção de Tipos de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tipos de Dados Atuais:\n",
      "ID                        int64\n",
      "Cargo                    object\n",
      "Experiencia_Anos        float64\n",
      "Salario_Anual_USD         int64\n",
      "Localizacao              object\n",
      "Educacao                 object\n",
      "Data_Contratacao         object\n",
      "Avaliacao_Desempenho    float64\n",
      "Empresa_Tamanho          object\n",
      "Bonus_Percentual        float64\n",
      "dtype: object\n",
      "\n",
      "Tipos de Dados Após Correção:\n",
      "ID                               int64\n",
      "Cargo                         category\n",
      "Experiencia_Anos               float64\n",
      "Salario_Anual_USD                int64\n",
      "Localizacao                   category\n",
      "Educacao                      category\n",
      "Data_Contratacao        datetime64[ns]\n",
      "Avaliacao_Desempenho           float64\n",
      "Empresa_Tamanho               category\n",
      "Bonus_Percentual               float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTipos de Dados Atuais:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Convertendo 'Data_Contratacao' para o tipo datetime\n",
    "df['Data_Contratacao'] = pd.to_datetime(df['Data_Contratacao'])\n",
    "\n",
    "# Podemos também converter colunas categóricas para o tipo 'category' para otimização de memória\n",
    "df['Cargo'] = df['Cargo'].astype('category')\n",
    "df['Localizacao'] = df['Localizacao'].astype('category')\n",
    "df['Educacao'] = df['Educacao'].astype('category')\n",
    "df['Empresa_Tamanho'] = df['Empresa_Tamanho'].astype('category')\n",
    "\n",
    "print(\"\\nTipos de Dados Após Correção:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Normalização (Min-Max Scaling)\n",
    "Normalização escala os valores numéricos para um intervalo específico, geralmente entre 0 e 1.\n",
    "Isso é útil para algoritmos que são sensíveis à escala das features (e.g., K-Means, SVMs).\n",
    "\n",
    "Fórmula: $X_{normalized} = (X - X_{min}) / (X_{max} - X_{min})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame após Normalização (Min-Max Scaling):\n",
      "   Salario_Anual_USD  Salario_Anual_USD_Normalized  Experiencia_Anos  Experiencia_Anos_Normalized\n",
      "0              85000                      0.315789               3.0                     0.285714\n",
      "1             120000                      0.684211               5.0                     0.571429\n",
      "2              60000                      0.052632               2.0                     0.142857\n",
      "3              90000                      0.368421               3.5                     0.357143\n",
      "4             150000                      1.000000               8.0                     1.000000\n"
     ]
    }
   ],
   "source": [
    "# Normalizando 'Salario_Anual_USD' e 'Experiencia_Anos' (após preencher NaNs)\n",
    "# Usaremos o df_filled para esta etapa, pois já tratamos os NaNs\n",
    "df_normalized = df_filled.copy()\n",
    "\n",
    "# Normalizando 'Salario_Anual_USD'\n",
    "min_salario = df_normalized['Salario_Anual_USD'].min()\n",
    "max_salario = df_normalized['Salario_Anual_USD'].max()\n",
    "df_normalized['Salario_Anual_USD_Normalized'] = (df_normalized['Salario_Anual_USD'] - min_salario) / (max_salario - min_salario)\n",
    "\n",
    "# Normalizando 'Experiencia_Anos'\n",
    "min_experiencia = df_normalized['Experiencia_Anos'].min()\n",
    "max_experiencia = df_normalized['Experiencia_Anos'].max()\n",
    "df_normalized['Experiencia_Anos_Normalized'] = (df_normalized['Experiencia_Anos'] - min_experiencia) / (max_experiencia - min_experiencia)\n",
    "\n",
    "print(\"\\nDataFrame após Normalização (Min-Max Scaling):\")\n",
    "print(df_normalized[['Salario_Anual_USD', 'Salario_Anual_USD_Normalized', 'Experiencia_Anos', 'Experiencia_Anos_Normalized']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Padronização (Standardization - Z-score normalization)\n",
    "Padronização escala os valores para que tenham média 0 e desvio padrão 1.\n",
    "Fórmula: $X_{standardized} = (X - \\mu) / \\sigma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame após Padronização (Standardization):\n",
      "   Salario_Anual_USD  Salario_Anual_USD_Standardized  Experiencia_Anos  Experiencia_Anos_Standardized\n",
      "0              85000                       -0.335055               3.0                      -0.471405\n",
      "1             120000                        0.747430               5.0                       0.471405\n",
      "2              60000                       -1.108258               2.0                      -0.942809\n",
      "3              90000                       -0.180414               3.5                      -0.235702\n",
      "4             150000                        1.675274               8.0                       1.885618\n"
     ]
    }
   ],
   "source": [
    "# Padronizando 'Salario_Anual_USD' e 'Experiencia_Anos'\n",
    "df_standardized = df_filled.copy()\n",
    "\n",
    "# Padronizando 'Salario_Anual_USD'\n",
    "mean_salario = df_standardized['Salario_Anual_USD'].mean()\n",
    "std_salario = df_standardized['Salario_Anual_USD'].std()\n",
    "df_standardized['Salario_Anual_USD_Standardized'] = (df_standardized['Salario_Anual_USD'] - mean_salario) / std_salario\n",
    "\n",
    "# Padronizando 'Experiencia_Anos'\n",
    "mean_experiencia = df_standardized['Experiencia_Anos'].mean()\n",
    "std_experiencia = df_standardized['Experiencia_Anos'].std()\n",
    "df_standardized['Experiencia_Anos_Standardized'] = (df_standardized['Experiencia_Anos'] - mean_experiencia) / std_experiencia\n",
    "\n",
    "print(\"\\nDataFrame após Padronização (Standardization):\")\n",
    "print(df_standardized[['Salario_Anual_USD', 'Salario_Anual_USD_Standardized', 'Experiencia_Anos', 'Experiencia_Anos_Standardized']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula 5: Manipulação de DataFrames: Filtragem, Ordenação, Criação de Novas Colunas\n",
    "\n",
    "O `pandas` oferece ferramentas poderosas para manipular DataFrames.\n",
    "\n",
    "#### 5.1 Filtragem de Dados\n",
    "Podemos selecionar subconjuntos de dados com base em condições."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame filtrado por 'Cientista de Dados':\n",
      "    ID               Cargo  Experiencia_Anos  Salario_Anual_USD     Localizacao   Educacao Data_Contratacao  Avaliacao_Desempenho Empresa_Tamanho  Bonus_Percentual\n",
      "0    1  Cientista de Dados               3.0              85000       São Paulo   Mestrado       2022-01-15                   4.5          Grande              0.10\n",
      "3    4  Cientista de Dados               NaN              90000  Belo Horizonte   Mestrado       2021-11-01                   4.2          Grande              0.12\n",
      "7    8  Cientista de Dados               3.0              92000  Rio de Janeiro  Doutorado       2022-06-30                   4.3         Pequena              0.10\n",
      "11  12  Cientista de Dados               NaN              95000  Belo Horizonte  Graduação       2022-04-22                   4.4           Média              0.11\n",
      "\n",
      "DataFrame filtrado por Salário > 100000 e Localização 'São Paulo':\n",
      "   ID               Cargo  Experiencia_Anos  Salario_Anual_USD Localizacao       Educacao Data_Contratacao  Avaliacao_Desempenho Empresa_Tamanho  Bonus_Percentual\n",
      "4   5  Gerente de Projeto               8.0             150000   São Paulo  Pós-Graduação       2018-07-25                   4.9          Grande              0.20\n",
      "6   7    Engenheiro de ML               6.0             130000   São Paulo       Mestrado       2019-02-01                   4.7          Grande              0.18\n"
     ]
    }
   ],
   "source": [
    "# Filtrando por 'Cargo'\n",
    "df_cientista_dados = df[df['Cargo'] == 'Cientista de Dados']\n",
    "print(\"\\nDataFrame filtrado por 'Cientista de Dados':\")\n",
    "print(df_cientista_dados)\n",
    "\n",
    "# Filtrando por múltiplas condições (Salário > 100000 E Localização = 'São Paulo')\n",
    "df_sp_altosalario = df[(df['Salario_Anual_USD'] > 100000) & (df['Localizacao'] == 'São Paulo')]\n",
    "print(\"\\nDataFrame filtrado por Salário > 100000 e Localização 'São Paulo':\")\n",
    "print(df_sp_altosalario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Ordenação de Dados (`sort_values()`)\n",
    "Podemos ordenar o DataFrame por uma ou mais colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame ordenado por Salário (Decrescente):\n",
      "    ID                   Cargo  Experiencia_Anos  Salario_Anual_USD     Localizacao       Educacao Data_Contratacao  Avaliacao_Desempenho Empresa_Tamanho  Bonus_Percentual\n",
      "4    5      Gerente de Projeto               8.0             150000       São Paulo  Pós-Graduação       2018-07-25                   4.9          Grande              0.20\n",
      "10  11     Engenheiro de Dados               7.0             140000          Remoto       Mestrado       2019-10-10                   4.6          Grande              0.17\n",
      "6    7        Engenheiro de ML               6.0             130000       São Paulo       Mestrado       2019-02-01                   4.7          Grande              0.18\n",
      "1    2  Engenheiro de Software               5.0             120000          Remoto      Graduação       2020-05-20                   4.8           Média              0.15\n",
      "11  12      Cientista de Dados               NaN              95000  Belo Horizonte      Graduação       2022-04-22                   4.4           Média              0.11\n",
      "\n",
      "DataFrame ordenado por Cargo e Experiência:\n",
      "   ID               Cargo  Experiencia_Anos  Salario_Anual_USD     Localizacao   Educacao Data_Contratacao  Avaliacao_Desempenho Empresa_Tamanho  Bonus_Percentual\n",
      "5   6      Analista de BI               4.0              70000          Remoto  Graduação       2021-09-12                   4.1           Média              0.08\n",
      "2   3   Analista de Dados               2.0              60000  Rio de Janeiro  Graduação       2023-03-10                   3.9         Pequena              0.05\n",
      "9  10   Analista de Dados               2.0              63000       São Paulo  Graduação       2023-08-18                   4.0          Grande              0.06\n",
      "0   1  Cientista de Dados               3.0              85000       São Paulo   Mestrado       2022-01-15                   4.5          Grande              0.10\n",
      "7   8  Cientista de Dados               3.0              92000  Rio de Janeiro  Doutorado       2022-06-30                   4.3         Pequena              0.10\n"
     ]
    }
   ],
   "source": [
    "# Ordenando por 'Salario_Anual_USD' em ordem decrescente\n",
    "df_ordenado_salario = df.sort_values(by='Salario_Anual_USD', ascending=False)\n",
    "print(\"\\nDataFrame ordenado por Salário (Decrescente):\")\n",
    "print(df_ordenado_salario.head())\n",
    "\n",
    "# Ordenando por 'Cargo' (ascendente) e depois por 'Experiencia_Anos' (decrescente)\n",
    "df_ordenado_multi = df.sort_values(by=['Cargo', 'Experiencia_Anos'], ascending=[True, False])\n",
    "print(\"\\nDataFrame ordenado por Cargo e Experiência:\")\n",
    "print(df_ordenado_multi.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Criação de Novas Colunas\n",
    "Podemos criar novas colunas a partir de colunas existentes ou de lógica de negócio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame com nova coluna 'Salario_Mensal_USD':\n",
      "   Salario_Anual_USD  Salario_Mensal_USD\n",
      "0              85000         7083.333333\n",
      "1             120000        10000.000000\n",
      "2              60000         5000.000000\n",
      "3              90000         7500.000000\n",
      "4             150000        12500.000000\n",
      "\n",
      "DataFrame com nova coluna 'Tempo_Empresa_Anos':\n",
      "  Data_Contratacao  Tempo_Empresa_Anos\n",
      "0       2022-01-15            3.449692\n",
      "1       2020-05-20            5.106092\n",
      "2       2023-03-10            2.302533\n",
      "3       2021-11-01            3.655031\n",
      "4       2018-07-25            6.926762\n",
      "\n",
      "DataFrame com nova coluna 'Salario_Categoria':\n",
      "   Salario_Anual_USD Salario_Categoria\n",
      "0              85000             Médio\n",
      "1             120000              Alto\n",
      "2              60000             Baixo\n",
      "3              90000             Médio\n",
      "4             150000              Alto\n"
     ]
    }
   ],
   "source": [
    "# Criando uma coluna 'Salario_Mensal'\n",
    "df['Salario_Mensal_USD'] = df['Salario_Anual_USD'] / 12\n",
    "print(\"\\nDataFrame com nova coluna 'Salario_Mensal_USD':\")\n",
    "print(df[['Salario_Anual_USD', 'Salario_Mensal_USD']].head())\n",
    "\n",
    "# Criando uma coluna 'Tempo_Empresa_Anos' a partir de 'Data_Contratacao'\n",
    "# Assumindo a data atual como 2025-06-28\n",
    "data_atual = pd.to_datetime('2025-06-28')\n",
    "df['Tempo_Empresa_Anos'] = (data_atual - df['Data_Contratacao']).dt.days / 365.25\n",
    "print(\"\\nDataFrame com nova coluna 'Tempo_Empresa_Anos':\")\n",
    "print(df[['Data_Contratacao', 'Tempo_Empresa_Anos']].head())\n",
    "\n",
    "# Criando uma coluna 'Salario_Categoria' baseada em faixas de salário\n",
    "def categorizar_salario(salario):\n",
    "    if salario < 70000:\n",
    "        return 'Baixo'\n",
    "    elif 70000 <= salario < 120000:\n",
    "        return 'Médio'\n",
    "    else:\n",
    "        return 'Alto'\n",
    "\n",
    "df['Salario_Categoria'] = df['Salario_Anual_USD'].apply(categorizar_salario)\n",
    "print(\"\\nDataFrame com nova coluna 'Salario_Categoria':\")\n",
    "print(df[['Salario_Anual_USD', 'Salario_Categoria']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula 6: Projeto Prático: Preparação de um Dataset sobre Empregos e Salários\n",
    "\n",
    "Vamos aplicar todas as técnicas aprendidas para preparar nosso dataset de exemplo para uma análise posterior.\n",
    "\n",
    "**Passo a passo:**\n",
    "\n",
    "1.  **Carregar o dataset** (já fizemos isso, mas vamos usar uma cópia limpa para o projeto).\n",
    "2.  **Inspecionar o dataset:** `info()`, `isnull().sum()`, `describe()`.\n",
    "3.  **Tratar valores ausentes:** Preencher `Experiencia_Anos` com a mediana.\n",
    "4.  **Corrigir tipos de dados:** Converter `Data_Contratacao` para datetime e categóricas para 'category'.\n",
    "5.  **Criar novas colunas:**\n",
    "    * `Salario_Total_Com_Bonus`: `Salario_Anual_USD * (1 + Bonus_Percentual)`\n",
    "    * `Decada_Contratacao`: Extrair a década da `Data_Contratacao`.\n",
    "6.  **Normalizar/Padronizar:** Padronizar `Salario_Total_Com_Bonus` e `Experiencia_Anos`.\n",
    "7.  **Remover colunas desnecessárias** (opcional, para este exemplo, manteremos todas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula 7: Conclusão\n",
    "\n",
    "Nesta aula, você aprendeu técnicas essenciais para limpeza e preparação de dados, incluindo:\n",
    "* Identificação e tratamento de valores ausentes usando `dropna()` e `fillna()`.\n",
    "* Correção de tipos de dados e aplicação de normalização/padronização.\n",
    "* Manipulação de DataFrames através de filtragem, ordenação e criação de novas colunas.\n",
    "\n",
    "A preparação de dados é uma etapa iterativa e crucial que impacta diretamente a qualidade e a confiabilidade de suas análises e modelos de machine learning. Com essas habilidades, você está mais preparado para trabalhar com dados do mundo real."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
